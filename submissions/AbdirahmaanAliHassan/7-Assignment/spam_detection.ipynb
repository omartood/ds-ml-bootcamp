{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f2c997-5274-421d-8427-b4cac193fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "CSV_PATH = \"mail_l7_dataset.csv\" \n",
    "\n",
    "# -----------------------------\n",
    "# Load & clean\n",
    "# -----------------------------\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    raise FileNotFoundError(f\"CSV not found: {CSV_PATH}\")\n",
    "\n",
    "# Expecting columns: Category (spam/ham or 0/1), Message (text)\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Replace NaNs\n",
    "df = df.where(pd.notnull(df), \"\")\n",
    "\n",
    "# Encode labels => spam=0, ham=1 (handles already numeric too)\n",
    "if df[\"Category\"].dtype == \"O\":\n",
    "    low = df[\"Category\"].str.lower().str.strip()\n",
    "    df.loc[low == \"spam\", \"Category\"] = 0\n",
    "    df.loc[low == \"ham\",  \"Category\"] = 1\n",
    "\n",
    "df[\"Category\"] = pd.to_numeric(df[\"Category\"], errors=\"coerce\")\n",
    "before = len(df)\n",
    "df = df.dropna(subset=[\"Category\"]).copy()\n",
    "df[\"Category\"] = df[\"Category\"].astype(int)\n",
    "dropped = before - len(df)\n",
    "if dropped:\n",
    "    print(f\"Dropped {dropped} rows due to unmapped Category labels.\")\n",
    "\n",
    "# -----------------------------\n",
    "# Split X/y\n",
    "# -----------------------------\n",
    "X = df[\"Message\"].astype(str)\n",
    "y = df[\"Category\"].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# TF-IDF (unigrams + bigrams)\n",
    "# -----------------------------\n",
    "tfidf = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words=\"english\",   # remove if your data isn't English\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "X_train_features = tfidf.fit_transform(X_train)\n",
    "X_test_features  = tfidf.transform(X_test)\n",
    "\n",
    "# -----------------------------\n",
    "# Models\n",
    "# -----------------------------\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000, random_state=RANDOM_STATE)\n",
    "lr.fit(X_train_features, y_train)\n",
    "y_pred_lr = lr.predict(X_test_features)\n",
    "\n",
    "# Random Forest (dense)\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "rf.fit(X_train_features.toarray(), y_train)\n",
    "y_pred_rf = rf.predict(X_test_features.toarray())\n",
    "\n",
    "# Naive Bayes (Multinomial)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_features, y_train)\n",
    "y_pred_nb = nb.predict(X_test_features)\n",
    "\n",
    "# -----------------------------\n",
    "# output results\n",
    "# -----------------------------\n",
    "def report_block(name, y_true, y_pred, pos_label=0):\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, pos_label=pos_label, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, pos_label=pos_label, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred, pos_label=pos_label, zero_division=0)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])  # [[TN, FP], [FN, TP]]\n",
    "\n",
    "    a, b, c, d = int(cm[0,0]), int(cm[0,1]), int(cm[1,0]), int(cm[1,1])\n",
    "\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Accuracy  : {acc:.2f}\")\n",
    "    print(f\"  Precision : {prec:.2f}\")\n",
    "    print(f\"  Recall    : {rec:.2f}\")\n",
    "    print(f\"  F1-Score  : {f1:.2f}\")\n",
    "    print(\"  Confusion Matrix:\")\n",
    "    print(f\"    [[{a:>3} {b:>3}]\")\n",
    "    print(f\"     [ {c:>3} {d:>3}]]\")\n",
    "\n",
    "print(\"Logistic Regression Performance\")\n",
    "report_block(\"Logistic Regression Performance\", y_test, y_pred_lr, pos_label=0)\n",
    "print()\n",
    "print(\"Random Forest Performance\")\n",
    "report_block(\"Random Forest Performance\", y_test, y_pred_rf, pos_label=0)\n",
    "print()\n",
    "print(\"Naive Bayes Performance\")\n",
    "report_block(\"Naive Bayes Performance\", y_test, y_pred_nb, pos_label=0)\n",
    "\n",
    "# -----------------------------\n",
    "# metrics JSON output\n",
    "# -----------------------------\n",
    "def gather_metrics(y_true, y_pred, pos_label=0):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    return {\n",
    "        \"accuracy\":  float(accuracy_score(y_true, y_pred)),\n",
    "        \"precision\": float(precision_score(y_true, y_pred, pos_label=pos_label, zero_division=0)),\n",
    "        \"recall\":    float(recall_score(y_true, y_pred, pos_label=pos_label, zero_division=0)),\n",
    "        \"f1\":        float(f1_score(y_true, y_pred, pos_label=pos_label, zero_division=0)),\n",
    "        \"confusion_matrix\": cm.tolist()\n",
    "    }\n",
    "\n",
    "results = {\n",
    "    \"logistic_regression\": gather_metrics(y_test, y_pred_lr, pos_label=0),\n",
    "    \"random_forest\":       gather_metrics(y_test, y_pred_rf, pos_label=0),\n",
    "    \"naive_bayes\":         gather_metrics(y_test, y_pred_nb, pos_label=0)\n",
    "}\n",
    "with open(\"spam_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "# -----------------------------\n",
    "# Sanity-check messages (3 required)\n",
    "# -----------------------------\n",
    "def label_to_text(v):\n",
    "    return \"Ham\" if int(v) == 1 else \"Spam\"\n",
    "\n",
    "print(\"\\nPredictions for 3 sample test messages with labels: Ham or Spam.\")\n",
    "tests = [\n",
    "    \"Free entry in 2 a weekly competition!\",\n",
    "    \"I will meet you at the cafe tomorrow\",\n",
    "    \"Congratulations, you won a free ticket\",\n",
    "]\n",
    "for t in tests:\n",
    "    v = tfidf.transform([t])\n",
    "    p_lr = lr.predict(v)[0]\n",
    "    p_rf = rf.predict(v.toarray())[0]\n",
    "    p_nb = nb.predict(v)[0]\n",
    "    print(f\"\\nText: {t!r}\")\n",
    "    print(f\"  Logistic Regression: {label_to_text(p_lr)}\")\n",
    "    print(f\"  Random Forest      : {label_to_text(p_rf)}\")\n",
    "    print(f\"  Naive Bayes        : {label_to_text(p_nb)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083af017-fa69-4ffd-81d1-992a1552af34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53717c65-87d2-4194-a3a9-40962129b4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
