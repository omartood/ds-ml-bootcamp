{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfdc4907-a774-4ab7-9cc0-923c76841631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# --------------------------------\n",
    "# 1) Load the cleaned dataset\n",
    "# --------------------------------\n",
    "CSV_PATH = \"clean_house_l5_dataset.csv\"\n",
    "df = pd.read_csv(CSV_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c91b610-4e54-41e5-b4a1-c9da0f00b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# 2) Split features (X) and target (y)\n",
    "# --------------------------------\n",
    "# We predict \"Price\". We also drop \"LogPrice\" from X so we don't leak target info.\n",
    "X = df.drop(columns=[\"Price\", \"LogPrice\"])\n",
    "y = df[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75f9b48d-eb30-42c6-99f2-f30c48bcbd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# 3) Train/test split for fair evaluation\n",
    "# --------------------------------\n",
    "# Keep 20% of data for testing generalization. random_state for reproducibility.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4424d184-de2e-4080-b75d-ab9214986450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# 4) Train Linear Regression\n",
    "# --------------------------------\n",
    "# Linear model is simple and interpretable; good baseline.\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fc50481-977c-4d8f-b5fc-680b06fe3ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# 5) Train Random Forest\n",
    "# --------------------------------\n",
    "# Ensemble model captures non-linear relationships; often stronger than linear.\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ecf2b87-86ab-440a-8055-16b21c4ccf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# 6) Helper to print metrics nicely\n",
    "# --------------------------------\n",
    "def print_metrics(name, y_true, y_pred):\n",
    "    \"\"\"Print R², MAE, MSE, RMSE for a model's predictions.\"\"\"\n",
    "    r2  = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    print(f\"  R²   : {r2:.3f}\")          # higher is better (max = 1.0)\n",
    "    print(f\"  MAE  : {mae:,.0f}\")        # lower is better (absolute error)\n",
    "    print(f\"  MSE  : {mse:,.0f}\")        # lower is better (squared error)\n",
    "    print(f\"  RMSE : {rmse:,.0f}\")       # lower is better (same units as Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c184701-91fd-4cac-b598-6075e4f40ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear Regression Performance:\n",
      "  R²   : 0.848\n",
      "  MAE  : 63,086\n",
      "  MSE  : 5,718,940,941\n",
      "  RMSE : 75,624\n",
      "\n",
      "Random Forest Performance:\n",
      "  R²   : 0.859\n",
      "  MAE  : 52,524\n",
      "  MSE  : 5,283,317,455\n",
      "  RMSE : 72,686\n",
      "\n",
      "Single-row sanity check:\n",
      "  Actual Price: $554,800\n",
      "  LR Pred     : $594,041\n",
      "  RF Pred     : $557,028\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------\n",
    "# 7) Show results for both models\n",
    "# --------------------------------\n",
    "print_metrics(\"Linear Regression\", y_test, lr_pred)\n",
    "print_metrics(\"Random Forest\",   y_test, rf_pred)\n",
    "\n",
    "# --------------------------------\n",
    "# 8) Single-row prediction (sanity check)\n",
    "# --------------------------------\n",
    "# Pick one unseen row from X_test and predict both models.\n",
    "# Use iloc[[i]] (double brackets) to keep it as a DataFrame with column names\n",
    "i = 3\n",
    "x_one_df = X_test.iloc[[i]]   # 1-row DataFrame (keeps feature names)\n",
    "y_true   = y_test.iloc[i]     # scalar\n",
    "\n",
    "p_lr_one = float(lr.predict(x_one_df)[0])\n",
    "p_rf_one = float(rf.predict(x_one_df)[0])\n",
    "\n",
    "print(\"\\nSingle-row sanity check:\")\n",
    "print(f\"  Actual Price: ${y_true:,.0f}\")\n",
    "print(f\"  LR Pred     : ${p_lr_one:,.0f}\")\n",
    "print(f\"  RF Pred     : ${p_rf_one:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be531c98-2a44-4ac2-859e-9c38433996f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
