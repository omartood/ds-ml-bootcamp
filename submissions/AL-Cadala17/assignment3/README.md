# ğŸ› ï¸ Assignment 3: Data Preprocessing Pipeline

### ğŸ“‹ Overview
This folder contains the deliverables for a data preprocessing assignment. The task involved transforming a raw, messy dataset on car prices into a clean, machine-learning-ready format by handling common data issues such as missing values, duplicates, and outliers.

### ğŸ¯ Key Objectives
The core objectives of this assignment were to implement a robust and reproducible data preprocessing pipeline by performing the following steps:

* **Data Inspection**: ğŸ” Load and perform an initial inspection to identify key data issues.
* **Target Cleaning**: ğŸ§¹ Clean and format the target variable (`Price`) for numerical analysis.
* **Data Imputation**: ğŸ’§ Handle missing values using appropriate strategies for numerical and categorical features.
* **Duplicate Removal**: ğŸ—‘ï¸ Identify and remove duplicate rows to ensure data integrity.
* **Outlier Handling**: ğŸ“ˆ Manage extreme values using the IQR capping method.
* **Feature Transformation**: âœ¨ One-hot encode categorical features and engineer new features to improve model performance.
* **Feature Scaling**: âš–ï¸ Standardize continuous features, ensuring the target variable is not scaled to prevent data leakage.
* **Finalization**: âœ… Perform final checks and save the preprocessed data to a new CSV file.

### ğŸ“‚ Included Files
This assignment includes the following files:

* `car_l3_dataset.csv`: The original, raw dataset used for this assignment.
* `l3_preprocess.py`: A Python script that implements all the data preprocessing steps from start to finish.
* `car_l3_clean_ready.csv`: The final, cleaned and preprocessed dataset generated by the script.
* `reflection.md`: A markdown document explaining the key decisions and reasoning behind the major steps in the preprocessing pipeline.
* `requirements.txt`: A file listing the exact Python packages and their versions required to run the script.