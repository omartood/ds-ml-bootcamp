{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "b05a0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "863f9c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset load\n",
    "df = pd.read_csv(\"mail_l7_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "45dbc5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message\n",
       "0         1  Go until jurong point, crazy.. Available only ...\n",
       "1         1                      Ok lar... Joking wif u oni...\n",
       "2         0  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         1  U dun say so early hor... U c already then say...\n",
       "4         1  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Label Encoding\n",
    "df['Category'] = df['Category'].str.lower().str.strip().map({\"spam\": 0, \"ham\": 1})  # ham rows  = 4,825.  spam rows = 747.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "72a22f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. seperate features and labels\n",
    "x = df[\"Message\"].astype(str) \n",
    "y = df[\"Category\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "00e5272b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SPLIT SIZES ===\n",
      "Train Data: 4457  | Test Data: 1115\n"
     ]
    }
   ],
   "source": [
    "# 4. split the dataset  into train and test\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.2, random_state=42)\n",
    "print(\"=== SPLIT SIZES ===\")\n",
    "print(\"Train Data:\", x_train.shape[0], \" | Test Data:\", x_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "f29320b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TF-IDF SHAPES ===\n",
      "X_train: (4457, 7440)  | X_test: (1115, 7440)\n"
     ]
    }
   ],
   "source": [
    "# 5. TF-IDF features\n",
    "vectorizer = TfidfVectorizer(min_df=1, stop_words=\"english\", lowercase= True)\n",
    "x_train_Features = vectorizer.fit_transform(x_train)\n",
    "x_test_Features = vectorizer.transform(x_test) \n",
    "print(\"=== TF-IDF SHAPES ===\")\n",
    "print(\"X_train:\", x_train_Features.shape, \" | X_test:\", x_test_Features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "6428c4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LR prediction\n",
       "1                1002\n",
       "0                 113\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Train the model by using LogisticRegression\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "# fit the model\n",
    "lr.fit(x_train_Features,y_train)\n",
    "# pridect the model\n",
    "lr_pred = lr.predict(x_test_Features)\n",
    "# convert the predictions of the LogisticRegression model to a DataFrame\n",
    "lr_pred_df = pd.DataFrame(lr_pred, columns=[\"LR prediction\"])\n",
    "# lr_pred_df.head(30)\n",
    "lr_pred_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "310e4734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RF prediction\n",
       "1                985\n",
       "0                130\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Train the model by using a RandomForest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "# fit the model\n",
    "rf.fit(x_train_Features,y_train)\n",
    "# pridect the model\n",
    "rf_pred = rf.predict(x_test_Features)\n",
    "# convert the predictions of the RandomForest Classifier model to a DataFrame\n",
    "rf_pred_df = pd.DataFrame(rf_pred, columns=[\"RF prediction\"])\n",
    "# rf_pred_df.head(30)\n",
    "rf_pred_df.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "16b8d1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NB prediction\n",
       "1                992\n",
       "0                123\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Train the model by using Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "# fit the model\n",
    "nb.fit(x_train_Features,y_train)\n",
    "# pridect the model\n",
    "nb_pred = nb.predict(x_test_Features)\n",
    "# convert the predictions of the Naive Bayes model to a DataFrame\n",
    "nb_pred_df = pd.DataFrame(nb_pred, columns=[\"NB prediction\"])\n",
    "# nb_pred_df.head(30)\n",
    "nb_pred_df.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "27c6c8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Performance: \n",
      "Accuracy (Overall): 0.97\n",
      "Precision (Spam=0): 1.00\n",
      "Recall (Spam=0):    0.76\n",
      "F1-Score (Spam=0):  0.86\n",
      "\n",
      "Logistic Regression Confusion matrix: \n",
      "                Pred Ham(1)  Pred Spam(0)\n",
      "Actual Ham(1)           966             0\n",
      "Actual Spam(0)           36           113\n",
      "\n",
      "Random Forest Performance: \n",
      "Accuracy (Overall): 0.98\n",
      "Precision (Spam=0): 1.00\n",
      "Recall (Spam=0):    0.87\n",
      "F1-Score (Spam=0):  0.93\n",
      "\n",
      "Random Forest Confusion matrix: \n",
      "                Pred Ham(1)  Pred Spam(0)\n",
      "Actual Ham(1)           966             0\n",
      "Actual Spam(0)           19           130\n",
      "\n",
      "Naive Bayes Performance: \n",
      "Accuracy (Overall): 0.98\n",
      "Precision (Spam=0): 1.00\n",
      "Recall (Spam=0):    0.83\n",
      "F1-Score (Spam=0):  0.90\n",
      "\n",
      "Naive Bayes Confusion matrix: \n",
      "                Pred Ham(1)  Pred Spam(0)\n",
      "Actual Ham(1)           966             0\n",
      "Actual Spam(0)           26           123\n"
     ]
    }
   ],
   "source": [
    "# 8. Evaluating the perforance of the models by using Metrics\n",
    "def display_metrics(model_name,y_actual,y_pred):\n",
    "    # Calculate all metrics, ensuring pos_label=0 for Precision, Recall, and F1\n",
    "    accuracy = accuracy_score(y_actual,y_pred)\n",
    "    precision = precision_score(y_actual,y_pred,pos_label=0)\n",
    "    recall = recall_score(y_actual,y_pred,pos_label=0)\n",
    "    f1 = f1_score(y_actual,y_pred,pos_label=0)\n",
    "    # Dispalying the result\n",
    "    print(f\"\\n{model_name} Performance: \")\n",
    "    print(f\"Accuracy (Overall): {accuracy:.2f}\")\n",
    "    print(f\"Precision (Spam=0): {precision:.2f}\")\n",
    "    print(f\"Recall (Spam=0):    {recall:.2f}\")\n",
    "    print(f\"F1-Score (Spam=0):  {f1:.2f}\")\n",
    "\n",
    "# Dispalying the Confusin Matrix \n",
    "def show_confusion_matrix(model_name,y_actual,y_pred):\n",
    "    cm = confusion_matrix(y_actual,y_pred,labels=[1,0])\n",
    "    print(f\"\\n{model_name} Confusion matrix: \")\n",
    "    cm_df = pd.DataFrame(cm,\n",
    "                         index=[\"Actual Ham(1)\", \"Actual Spam(0)\"],\n",
    "                         columns=[\"Pred Ham(1)\", \"Pred Spam(0)\"]\n",
    "                         )\n",
    "    print(cm_df)\n",
    "\n",
    "# print the evaluation metrics for the models\n",
    "display_metrics(\"Logistic Regression\",y_test,lr_pred)\n",
    "show_confusion_matrix(\"Logistic Regression\",y_test,lr_pred)\n",
    "\n",
    "display_metrics(\"Random Forest\",y_test,rf_pred)\n",
    "show_confusion_matrix(\"Random Forest\",y_test,rf_pred)\n",
    "\n",
    "display_metrics(\"Naive Bayes\",y_test,nb_pred)\n",
    "show_confusion_matrix(\"Naive Bayes\",y_test,nb_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "9963996f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:Ham(1) |LR pred:Ham(1) |RF pred:Ham(1) |NB pred:Ham(1)\n",
      "Actual:Spm(0) |LR pred:Ham(1) |RF pred:Spm(0) |NB pred:Ham(1)\n",
      "Actual:Spm(0) |LR pred:Spm(0) |RF pred:Spm(0) |NB pred:Spm(0)\n",
      "Actual:Spm(0) |LR pred:Ham(1) |RF pred:Spm(0) |NB pred:Spm(0)\n",
      "Actual:Ham(1) |LR pred:Ham(1) |RF pred:Ham(1) |NB pred:Ham(1)\n"
     ]
    }
   ],
   "source": [
    "# 9. sanity check (for the test data)\n",
    "# this function will change the label output to a string like 1-> ham and 0-> spam\n",
    "def label_to_str(r):\n",
    " return \"Spm(0)\" if r == 0 else \"Ham(1)\"\n",
    "\n",
    "i = 905\n",
    "while i < 910:\n",
    " sample_test =  x_test.iloc[i]\n",
    " Actual_Label = y_test.iloc[i]\n",
    "\n",
    " lr_pred_test = int(lr.predict(vectorizer.transform([sample_test]))[0])\n",
    " rf_pred_test = int(rf.predict(vectorizer.transform([sample_test]))[0])\n",
    " nb_pred_test = int(nb.predict(vectorizer.transform([sample_test]))[0])\n",
    "\n",
    " print(f\"Actual:{label_to_str(Actual_Label)} |LR pred:{label_to_str(lr_pred_test)} |RF pred:{label_to_str(rf_pred_test)} |NB pred:{label_to_str(nb_pred_test)}\")\n",
    " i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "ddca3d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SAMPLE MESSAGE PREDICTIONS ===\n",
      "\n",
      "Sample Message: Free entry in 2 a weekly competition!\n",
      "LR pred: Ham (1)\n",
      "RF pred: Ham (1)\n",
      "NB pred: Spam (0)\n",
      "\n",
      "\n",
      "Sample Message: I will meet you at the cafe tomorrow\n",
      "LR pred: Ham (1)\n",
      "RF pred: Ham (1)\n",
      "NB pred: Ham (1)\n",
      "\n",
      "\n",
      "Sample Message: Congratulations, you won a free ticket\n",
      "LR pred: Ham (1)\n",
      "RF pred: Ham (1)\n",
      "NB pred: Ham (1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10. sanity check (for the Sample Message)\n",
    "sample_message = [\n",
    "    \"Free entry in 2 a weekly competition!\",\n",
    "    \"I will meet you at the cafe tomorrow\",\n",
    "    \"Congratulations, you won a free ticket\",\n",
    "]\n",
    "\n",
    "# this function will change the label output to string like: 1-> ham and 0-> spam\n",
    "def label_to_str(r):\n",
    " return \"Spam (0)\" if r == 0 else \"Ham (1)\"\n",
    "\n",
    "\n",
    "print(\"\\n=== SAMPLE MESSAGE PREDICTIONS ===\")\n",
    "for i in sample_message:\n",
    " lr_pred_sample = int(lr.predict(vectorizer.transform([i]))[0])\n",
    " rf_pred_sample = int(rf.predict(vectorizer.transform([i]))[0])\n",
    " nb_pred_sample = int(nb.predict(vectorizer.transform([i]))[0])\n",
    " #\n",
    " print(f\"\\nSample Message: {i}\")\n",
    " print(f\"LR pred: {label_to_str(lr_pred_sample)}\") \n",
    " print(f\"RF pred: {label_to_str(rf_pred_sample)}\")\n",
    " print(f\"NB pred: {label_to_str(nb_pred_sample)}\\n\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
